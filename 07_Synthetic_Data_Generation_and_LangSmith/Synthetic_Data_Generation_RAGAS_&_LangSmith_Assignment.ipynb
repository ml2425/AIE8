{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCk2Rx4cjlYF"
   },
   "source": [
    "# Synthetic Data Generation Using RAGAS - RAG Evaluation with LangSmith\n",
    "\n",
    "In the following notebook we'll explore a use-case for RAGAS' synthetic testset generation workflow!\n",
    "\n",
    "\n",
    "\n",
    "- 🤝 BREAKOUT ROOM #1\n",
    "  1. Use RAGAS to Generate Synthetic Data\n",
    "\n",
    "- 🤝 BREAKOUT ROOM #2\n",
    "  1. Load them into a LangSmith Dataset\n",
    "  2. Evaluate our RAG chain against the synthetic test data\n",
    "  3. Make changes to our pipeline\n",
    "  4. Evaluate the modified pipeline\n",
    "\n",
    "SDG is a critical piece of the puzzle, especially for early iteration! Without it, it would not be nearly as easy to get high quality early signal for our application's performance.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bG2ta-B478G"
   },
   "source": [
    "# 🤝 BREAKOUT ROOM #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VUI7vF_kbv9"
   },
   "source": [
    "## Task 1: Dependencies and API Keys\n",
    "\n",
    "We'll need to install a number of API keys and dependencies, since we'll be leveraging a number of great technologies for this pipeline!\n",
    "\n",
    "1. OpenAI's endpoints to handle the Synthetic Data Generation\n",
    "2. OpenAI's Endpoints for our RAG pipeline and LangSmith evaluation\n",
    "3. QDrant as our vectorstore\n",
    "4. LangSmith for our evaluation coordinator!\n",
    "\n",
    "Let's install and provide all the required information below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and API Keys:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Import\n",
    "\n",
    "To prevent errors that may occur based on OS - we'll import NLTK and download the needed packages to ensure correct handling of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mspla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mspla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LangChain API Key: ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also want to set a project name to make things easier for ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - SDG - {uuid4().hex[0:8]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI's API Key!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Test Data\n",
    "\n",
    "We wil be using Ragas to build out a set of synthetic test questions, references, and reference contexts. This is useful because it will allow us to find out how our system is performing.\n",
    "\n",
    "> NOTE: Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "We'll prepare our data - which should hopefull be familiar at this point since it's our Use-Case Data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load our data into a familiar LangChain format using the `DirectoryLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "\n",
    "path = \"data/\"\n",
    "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graph Based Synthetic Generation\n",
    "\n",
    "Ragas uses a knowledge graph based approach to create data. This is extremely useful as it allows us to create complex queries rather simply. The additional testset complexity allows us to evaluate larger problems more effectively, as systems tend to be very strong on simple evaluation tasks.\n",
    "\n",
    "Let's start by defining our `generator_llm` (which will generate our questions, summaries, and more), and our `generator_embeddings` which will be useful in building our graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrolled SDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to instantiate our Knowledge Graph.\n",
    "\n",
    "This graph will contain N number of nodes that have M number of relationships. These nodes and relationships (AKA \"edges\") will define our knowledge graph and be used later to construct relevant questions and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 0, relationships: 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step we're going to take is to simply insert each of our full documents into the graph. This will provide a base that we can apply transformations to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 64, relationships: 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import Node, NodeType\n",
    "\n",
    "### NOTICE: We're using a subset of the data for this example - this is to keep costs/time down.\n",
    "for doc in docs:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll apply the *default* transformations to our knowledge graph. This will take the nodes currently on the graph and transform them based on a set of [default transformations](https://docs.ragas.io/en/latest/references/transforms/#ragas.testset.transforms.default_transforms).\n",
    "\n",
    "These default transformations are dependent on the corpus length, in our case:\n",
    "\n",
    "- Producing Summaries -> produces summaries of the documents\n",
    "- Extracting Headlines -> finding the overall headline for the document\n",
    "- Theme Extractor -> extracts broad themes about the documents\n",
    "\n",
    "It then uses cosine-similarity and heuristics between the embeddings of the above transformations to construct relationships between the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f942f3d56c49eda357c6d127b58c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025d41a5209649c29303dfcc7a9703cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57432867193c478e8dd83fe200ca418e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node '3856dd'. Skipping!\n",
      "Property 'summary' already exists in node 'c0e8b5'. Skipping!\n",
      "Property 'summary' already exists in node '089ba8'. Skipping!\n",
      "Property 'summary' already exists in node '35ba75'. Skipping!\n",
      "Property 'summary' already exists in node '92f2ed'. Skipping!\n",
      "Property 'summary' already exists in node '684804'. Skipping!\n",
      "Property 'summary' already exists in node '829049'. Skipping!\n",
      "Property 'summary' already exists in node '28936b'. Skipping!\n",
      "Property 'summary' already exists in node '4d3ecd'. Skipping!\n",
      "Property 'summary' already exists in node '163ed5'. Skipping!\n",
      "Property 'summary' already exists in node '97997b'. Skipping!\n",
      "Property 'summary' already exists in node '20f3f2'. Skipping!\n",
      "Property 'summary' already exists in node '4cc321'. Skipping!\n",
      "Property 'summary' already exists in node '6e25cf'. Skipping!\n",
      "Property 'summary' already exists in node '6a35a4'. Skipping!\n",
      "Property 'summary' already exists in node 'aebcf8'. Skipping!\n",
      "Property 'summary' already exists in node '12a6e2'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a646191c5e93403f9ea1b730f0017e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6418b6aeef7b45089605bf5c80ddff91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node '684804'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '089ba8'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '35ba75'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3856dd'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '92f2ed'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'c0e8b5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '97997b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '829049'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '163ed5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4d3ecd'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '28936b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '20f3f2'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4cc321'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '6e25cf'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '6a35a4'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'aebcf8'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '12a6e2'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f311dcfeaae4111a9673d1535ddbbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 86, relationships: 711)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "transformer_llm = generator_llm\n",
    "embedding_model = generator_embeddings\n",
    "\n",
    "default_transforms = default_transforms(documents=docs, llm=transformer_llm, embedding_model=embedding_model)\n",
    "apply_transforms(kg, default_transforms)\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save and load our knowledge graphs as follows."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kg.save(\"usecase_data_kg.json\")\n",
    "usecase_data_kg = KnowledgeGraph.load(\"usecase_data_kg.json\")\n",
    "usecase_data_kg\n",
    "\n",
    "\n",
    "# Windows Default: Windows uses cp1252 encoding which has limited Unicode support\n",
    "# RAGAS Content: The knowledge graph contains Unicode characters (arrows, special symbols)\n",
    "# JSON Requirement: JSON needs UTF-8 to properly handle Unicode characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 86, relationships: 711)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from ragas.testset.graph import UUIDEncoder\n",
    "\n",
    "\"\"\"\n",
    "Explicit UTF-8: Forces the file to be saved/loaded with UTF-8 encoding\n",
    "\"\"\"\n",
    "\n",
    "# Save with explicit UTF-8 encoding\n",
    "data = {\n",
    "    \"nodes\": [node.model_dump() for node in kg.nodes],\n",
    "    \"relationships\": [rel.model_dump() for rel in kg.relationships],\n",
    "}\n",
    "\n",
    "with open(\"usecase_data_kg.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, cls=UUIDEncoder, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Load with explicit UTF-8 encoding\n",
    "with open(\"usecase_data_kg.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Reconstruct the knowledge graph\n",
    "from ragas.testset.graph import KnowledgeGraph, Node, Relationship\n",
    "\n",
    "usecase_data_kg = KnowledgeGraph()\n",
    "usecase_data_kg.nodes = [Node(**node_data) for node_data in data[\"nodes\"]]\n",
    "usecase_data_kg.relationships = [Relationship(**rel_data) for rel_data in data[\"relationships\"]]\n",
    "\n",
    "usecase_data_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our knowledge graph, we can construct a \"test set generator\" - which will allow us to create queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=embedding_model, knowledge_graph=usecase_data_kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we'd like to be able to define the kinds of queries we're generating - which is made simple by Ragas having pre-created a number of different \"QuerySynthesizer\"s.\n",
    "\n",
    "Each of these Synthetsizers is going to tackle a separate kind of query which will be generated from a scenario and a persona.\n",
    "\n",
    "In essence, Ragas will use an LLM to generate a persona of someone who would interact with the data - and then use a scenario to construct a question from that data and persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import default_query_distribution, SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
    "\n",
    "query_distribution = [\n",
    "        (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "        (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "        (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ Question #1:\n",
    "\n",
    "What are the three types of query synthesizers doing? Describe each one in simple terms.\n",
    "\n",
    "The \"hop\" refers to logical hops between different representations of the same content\n",
    "\n",
    "1. SingleHopSpecificQuerySyntehsizer:   Creates questions that can be answered with information from one single document or chunk. It does not need to connect different sources to find the answer. \n",
    "\n",
    "2. MultiHopAbstractQuerySynthesizer (25% of queries): Creates questions that require connecting multiple documents. Focus on asking general concepts or themes  \"Concept questioning\"\n",
    "\n",
    "3. MultiHopSpecificQuerySynthesizer (25% of queries)\n",
    "Creates questions that require connecting multiple documents but asks for specific details or facts\n",
    "Simple example: \"What are the specific AI applications in healthcare and how do they differ from those in finance?\" (needs specific details from multiple sources) \"Specific factual enquiry\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use our `TestSetGenerator` to generate our testset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51ad91e1a674125874852226bb133a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffbaec9ebf14bf183732897f4ba53f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8707144ccd544361a994cfc4d78e22cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the significance of Handa et al., 2025...</td>\n",
       "      <td>[Introduction ChatGPT launched in November 202...</td>\n",
       "      <td>The paper by Handa et al., 2025 reports statis...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is OpenAI known for?</td>\n",
       "      <td>[Table 1: ChatGPT daily message counts (millio...</td>\n",
       "      <td>OpenAI is associated with ChatGPT, which is us...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the significance of Appendix D in unde...</td>\n",
       "      <td>[Variation by Occupation Figure 23 presents va...</td>\n",
       "      <td>Appendix D contains a full report of GWA count...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the Practical Guidance in the context ...</td>\n",
       "      <td>[Conclusion This paper studies the rapid growt...</td>\n",
       "      <td>Practical Guidance is one of the three most co...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how much ChatGPT messages are non work and how...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nMonth Non-Work (M) (%) Work (M) (%...</td>\n",
       "      <td>In June 2024, non-work messages made up 53% of...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Based on the data showing the growth of non-wo...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nMonth Non-Work (M) (%) Work (M) (%...</td>\n",
       "      <td>The data indicates that non-work messages have...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>how chatgpt growth and user questions relate t...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
       "      <td>the paper shows chatgpt grew fast since nov 20...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Based on the rapid growth of ChatGPT usage in ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
       "      <td>The context indicates that by July 2025, ChatG...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wht US is the? how does it relate to ChatGPT u...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
       "      <td>The context indicates that ChatGPT usage in th...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Based on the rapid growth of ChatGPT, which ha...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
       "      <td>By July 2025, ChatGPT users were collectively ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does the rapid growth of ChatGPT to over 7...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
       "      <td>The first segment indicates that by July 2025,...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   What is the significance of Handa et al., 2025...   \n",
       "1                           What is OpenAI known for?   \n",
       "2   What is the significance of Appendix D in unde...   \n",
       "3   What is the Practical Guidance in the context ...   \n",
       "4   how much ChatGPT messages are non work and how...   \n",
       "5   Based on the data showing the growth of non-wo...   \n",
       "6   how chatgpt growth and user questions relate t...   \n",
       "7   Based on the rapid growth of ChatGPT usage in ...   \n",
       "8   Wht US is the? how does it relate to ChatGPT u...   \n",
       "9   Based on the rapid growth of ChatGPT, which ha...   \n",
       "10  How does the rapid growth of ChatGPT to over 7...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [Introduction ChatGPT launched in November 202...   \n",
       "1   [Table 1: ChatGPT daily message counts (millio...   \n",
       "2   [Variation by Occupation Figure 23 presents va...   \n",
       "3   [Conclusion This paper studies the rapid growt...   \n",
       "4   [<1-hop>\\n\\nMonth Non-Work (M) (%) Work (M) (%...   \n",
       "5   [<1-hop>\\n\\nMonth Non-Work (M) (%) Work (M) (%...   \n",
       "6   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
       "7   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
       "8   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
       "9   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
       "10  [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   The paper by Handa et al., 2025 reports statis...   \n",
       "1   OpenAI is associated with ChatGPT, which is us...   \n",
       "2   Appendix D contains a full report of GWA count...   \n",
       "3   Practical Guidance is one of the three most co...   \n",
       "4   In June 2024, non-work messages made up 53% of...   \n",
       "5   The data indicates that non-work messages have...   \n",
       "6   the paper shows chatgpt grew fast since nov 20...   \n",
       "7   The context indicates that by July 2025, ChatG...   \n",
       "8   The context indicates that ChatGPT usage in th...   \n",
       "9   By July 2025, ChatGPT users were collectively ...   \n",
       "10  The first segment indicates that by July 2025,...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_specific_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstracted SDG\n",
    "\n",
    "The above method is the full process - but we can shortcut that using the provided abstractions!\n",
    "\n",
    "This will generate our knowledge graph under the hood, and will - from there - generate our personas and scenarios to construct our queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03ecf2cd99048e9b309853068e810a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfe5be117ee4af2b21a67658f0731eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5683feeffa749a9b7888592d23a3c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node 'a76c46'. Skipping!\n",
      "Property 'summary' already exists in node '51afe8'. Skipping!\n",
      "Property 'summary' already exists in node 'cb6a16'. Skipping!\n",
      "Property 'summary' already exists in node 'da926b'. Skipping!\n",
      "Property 'summary' already exists in node '321ff5'. Skipping!\n",
      "Property 'summary' already exists in node '5171f1'. Skipping!\n",
      "Property 'summary' already exists in node '5ff6f3'. Skipping!\n",
      "Property 'summary' already exists in node '4fca9e'. Skipping!\n",
      "Property 'summary' already exists in node 'db9384'. Skipping!\n",
      "Property 'summary' already exists in node '7282c2'. Skipping!\n",
      "Property 'summary' already exists in node 'b4f6e0'. Skipping!\n",
      "Property 'summary' already exists in node 'ef8cf3'. Skipping!\n",
      "Property 'summary' already exists in node '934e3b'. Skipping!\n",
      "Property 'summary' already exists in node '5a1652'. Skipping!\n",
      "Property 'summary' already exists in node 'ccd60a'. Skipping!\n",
      "Property 'summary' already exists in node '971494'. Skipping!\n",
      "Property 'summary' already exists in node 'c88734'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5f4c3390de41f69df8e943aa6e909e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbcb9ecc8ad454da38eb8d1e31ed008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node 'da926b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '51afe8'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'a76c46'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'db9384'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '5171f1'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'cb6a16'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b4f6e0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4fca9e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '321ff5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '5ff6f3'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '7282c2'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'ef8cf3'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '934e3b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '5a1652'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'ccd60a'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '971494'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'c88734'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59169f5102d4c159e9baeffdf58f073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234f350392a84cbba8f79c41ac6e5505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a8da9a3ec24466b11b736d61ab7c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ede2ef44ef44a3f9e6754622fcc1730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs, testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is a Roth?</td>\n",
       "      <td>[Introduction ChatGPT launched in November 202...</td>\n",
       "      <td>The provided context does not include a defini...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the significance of June 2024 in the c...</td>\n",
       "      <td>[Table 1: ChatGPT daily message counts (millio...</td>\n",
       "      <td>The context reports on ChatGPT message counts ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChatGPT use work?</td>\n",
       "      <td>[Variation by Occupation Figure 23 presents va...</td>\n",
       "      <td>Variation by Occupation Figure 23 shows how Ch...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whn was November 2022 in relation to ChatGPT's...</td>\n",
       "      <td>[Conclusion This paper studies the rapid growt...</td>\n",
       "      <td>Conclusion This paper studies the rapid growth...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does variation in ChatGPT usage by occupat...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nVariation by Occupation Figure 23 ...</td>\n",
       "      <td>The context indicates that ChatGPT usage varie...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does the rapid adoption of ChatGPT, as evi...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nIntroduction ChatGPT launched in N...</td>\n",
       "      <td>The rapid adoption of ChatGPT, with its widesp...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do the differences in message types, such ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nVariation by Occupation Figure 23 ...</td>\n",
       "      <td>The data indicates that users in highly paid p...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hw does ChatGPT usage grow for work and non-wo...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nIntroduction ChatGPT launched in N...</td>\n",
       "      <td>The context indicates that since its launch in...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Considering the rapid growth of ChatGPT usage ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
       "      <td>The context indicates that in the US, ChatGPT ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wht US is the main focus of the ChatGPT growth...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
       "      <td>The study highlights that ChatGPT's rapid grow...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Whay did Handa et al. (2025) study the types o...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nIntroduction ChatGPT launched in N...</td>\n",
       "      <td>Handa et al. (2025) studied the types of messa...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How does the rapid growth of ChatGPT, as an Op...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nIntroduction ChatGPT launched in N...</td>\n",
       "      <td>The context indicates that ChatGPT, launched i...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0                                     What is a Roth?   \n",
       "1   What is the significance of June 2024 in the c...   \n",
       "2                                   ChatGPT use work?   \n",
       "3   Whn was November 2022 in relation to ChatGPT's...   \n",
       "4   How does variation in ChatGPT usage by occupat...   \n",
       "5   How does the rapid adoption of ChatGPT, as evi...   \n",
       "6   How do the differences in message types, such ...   \n",
       "7   Hw does ChatGPT usage grow for work and non-wo...   \n",
       "8   Considering the rapid growth of ChatGPT usage ...   \n",
       "9   Wht US is the main focus of the ChatGPT growth...   \n",
       "10  Whay did Handa et al. (2025) study the types o...   \n",
       "11  How does the rapid growth of ChatGPT, as an Op...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [Introduction ChatGPT launched in November 202...   \n",
       "1   [Table 1: ChatGPT daily message counts (millio...   \n",
       "2   [Variation by Occupation Figure 23 presents va...   \n",
       "3   [Conclusion This paper studies the rapid growt...   \n",
       "4   [<1-hop>\\n\\nVariation by Occupation Figure 23 ...   \n",
       "5   [<1-hop>\\n\\nIntroduction ChatGPT launched in N...   \n",
       "6   [<1-hop>\\n\\nVariation by Occupation Figure 23 ...   \n",
       "7   [<1-hop>\\n\\nIntroduction ChatGPT launched in N...   \n",
       "8   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
       "9   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
       "10  [<1-hop>\\n\\nIntroduction ChatGPT launched in N...   \n",
       "11  [<1-hop>\\n\\nIntroduction ChatGPT launched in N...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   The provided context does not include a defini...   \n",
       "1   The context reports on ChatGPT message counts ...   \n",
       "2   Variation by Occupation Figure 23 shows how Ch...   \n",
       "3   Conclusion This paper studies the rapid growth...   \n",
       "4   The context indicates that ChatGPT usage varie...   \n",
       "5   The rapid adoption of ChatGPT, with its widesp...   \n",
       "6   The data indicates that users in highly paid p...   \n",
       "7   The context indicates that since its launch in...   \n",
       "8   The context indicates that in the US, ChatGPT ...   \n",
       "9   The study highlights that ChatGPT's rapid grow...   \n",
       "10  Handa et al. (2025) studied the types of messa...   \n",
       "11  The context indicates that ChatGPT, launched i...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vSRr2MXk0P_"
   },
   "source": [
    "We'll need to provide our LangSmith API key, and set tracing to \"true\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLDUsLJg43k7"
   },
   "source": [
    "# 🤝 BREAKOUT ROOM #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SLtk1GtnyoY"
   },
   "source": [
    "## Task 4: LangSmith Dataset\n",
    "\n",
    "Now we can move on to creating a dataset for LangSmith!\n",
    "\n",
    "First, we'll need to create a dataset on LangSmith using the `Client`!\n",
    "\n",
    "We'll name our Dataset to make it easy to work with later."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "TLgm6OjvYSsm"
   },
   "source": [
    "# Does not work if this has been created on langsmith. Only one unique name\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"Use Case Synthetic Data - AIE8\"\n",
    "\n",
    "langsmith_dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Synthetic Data for Use Cases\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing dataset: Use Case Synthetic Data - AIE8\n"
     ]
    }
   ],
   "source": [
    "# check if dataset has been created on langsmith account, create only if not.\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"Use Case Synthetic Data - AIE8\"\n",
    "\n",
    "# Check if dataset already exists\n",
    "try:\n",
    "    # Try to get the existing dataset\n",
    "    langsmith_dataset = client.read_dataset(dataset_name=dataset_name)\n",
    "    print(f\"Using existing dataset: {dataset_name}\")\n",
    "except:\n",
    "    # If it doesn't exist, create it\n",
    "    langsmith_dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=\"Synthetic Data for Use Cases\"\n",
    "    )\n",
    "    print(f\"Created new dataset: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64SmXMBnzXWm"
   },
   "source": [
    "We'll iterate through the RAGAS created dataframe - and add each example to our created dataset!\n",
    "\n",
    "> NOTE: We need to conform the outputs to the expected format - which in this case is: `question` and `answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8nFQ6di_XnY7"
   },
   "outputs": [],
   "source": [
    "for data_row in dataset.to_pandas().iterrows():\n",
    "  client.create_example(\n",
    "      inputs={\n",
    "          \"question\": data_row[1][\"user_input\"]\n",
    "      },\n",
    "      outputs={\n",
    "          \"answer\": data_row[1][\"reference\"]\n",
    "      },\n",
    "      metadata={\n",
    "          \"context\": data_row[1][\"reference_contexts\"]\n",
    "      },\n",
    "      dataset_id=langsmith_dataset.id\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6EbQVyZq-2j"
   },
   "source": [
    "## Basic RAG Chain\n",
    "\n",
    "Time for some RAG!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4njbUAIsaYjB"
   },
   "outputs": [],
   "source": [
    "rag_documents = docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQorBy8H1AZR"
   },
   "source": [
    "To keep things simple, we'll just use LangChain's recursive character text splitter!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qWo3Ajaragv1"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "rag_documents = text_splitter.split_documents(rag_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kghuTb9R01oO"
   },
   "source": [
    "We'll create our vectorstore using OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UwfJCzP3aqKI"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpCLS-a01Ft2"
   },
   "source": [
    "As usual, we will power our RAG application with Qdrant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "58Ypj_NgbEsi"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=rag_documents,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"Use Case RAG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SbKSjfSkbTYo"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxUOMaQX1K2N"
   },
   "source": [
    "To get the \"A\" in RAG, we'll provide a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1sLeY1oWbVqO"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\\\n",
    "Given a provided context and question, you must answer the question based only on context.\n",
    "\n",
    "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZnHDh4e1Ou5"
   },
   "source": [
    "As is usual: We'll be using `gpt-4.1-mini` for our RAG!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6nx-ue1XbciV"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmTL6-pc1ZGz"
   },
   "source": [
    "Finally, we can set-up our RAG LCEL chain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "TjWj0OLIbbFc"
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WQ7bEweo4IIb",
    "outputId": "d161b269-f799-4920-d6ce-c202f6e783aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context from \"How People Use ChatGPT,\" people today use AI, particularly ChatGPT, for a variety of purposes that can be broadly classified into work-related and non-work-related uses. As of 2025, about 70% of ChatGPT queries are non-work-related, but usage for work tasks is also growing steadily.\\n\\nThe three most common conversation topics with ChatGPT are:\\n\\n1. **Practical Guidance** – General how-to advice and step-by-step instructions on various topics.\\n2. **Writing** – This is the dominant work-related use, accounting for 42% of work messages and includes modifying existing text and producing new written content.\\n3. **Seeking Information** – Users frequently ask for information or clarification to inform decisions.\\n\\nAdditional uses include:\\n\\n- **Tutoring or Teaching** (education-related queries make up 10.2% of messages),\\n- **Technical Help** (computing programming, mathematical calculations, data analysis),\\n- **Creative ideation** and some self-expression (although less common),\\n- **Games and Role Play** and **Relationships and Personal Reflection** are smaller usage segments.\\n\\nMany people use AI to assist with decision support and problem-solving, especially in knowledge-intensive and professional occupations. ChatGPT improves productivity by offering advice, research assistance, and customized outputs such as workout plans, new product ideas, or fantasy football team names, distinguishing it from traditional web searches.\\n\\nOverall, AI is used for:\\n\\n- Asking questions to get advice or information,\\n- Doing tasks that produce specific outputs,\\n- Expressing views or feelings (to a smaller extent).\\n\\nIn summary, people are predominantly using AI for practical guidance, writing and editing, seeking information, education, technical support, creative ideation, and decision support in both work and everyday life contexts.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"question\" : \"What are people doing with AI these days?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9hBh5YPrdGJ"
   },
   "source": [
    "## LangSmith Evaluation Set-up\n",
    "\n",
    "We'll use OpenAI's GPT-4.1 as our evaluation LLM for our base Evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "gfwPYdIkcvpF"
   },
   "outputs": [],
   "source": [
    "eval_llm = ChatOpenAI(model=\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b8pToKH2K28"
   },
   "source": [
    "We'll be using a number of evaluators - from LangSmith provided evaluators, to a few custom evaluators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "PXSG-_ajckp6"
   },
   "outputs": [],
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
    "\n",
    "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : eval_llm})\n",
    "\n",
    "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
    "    \"labeled_criteria\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"helpfulness\": (\n",
    "                \"Is this submission helpful to the user,\"\n",
    "                \" taking into account the correct reference answer?\"\n",
    "            )\n",
    "        },\n",
    "        \"llm\" : eval_llm\n",
    "    },\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"output\"],\n",
    "        \"reference\": example.outputs[\"answer\"],\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "dopeness_evaluator = LangChainStringEvaluator(\n",
    "    \"criteria\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"dopeness\": \"Is this response dope, lit, cool, or is it just a generic response?\",\n",
    "        },\n",
    "        \"llm\" : eval_llm\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0SQP_FoCetP"
   },
   "source": [
    "#### 🏗️ Activity #2:\n",
    "\n",
    "Highlight what each evaluator is evaluating.\n",
    "\n",
    "- `qa_evaluator`:\n",
    "- `labeled_helpfulness_evaluator`:\n",
    "- `dopeness_evaluator`:\n",
    "\n",
    "qa evaluator -- is used to judge llm predicted answer against reference answer from document texts. Measures accuracy of reponse.\n",
    "\n",
    "labeled_healthfulness_evaluator -- while an answer may be accurate, but is it useful? Measures usefulness of response.\n",
    "\n",
    "dopeness_evaluator -- is used to assess ability to engage maintain user interest, instead of plain bland texts. Measures engagement factor, and to some extent 'quality' response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R35sQMHVrnpl"
   },
   "source": [
    "## LangSmith Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "122b1bd1f0e9417a8dcb57d4eebe4d2e",
      "e0c233ad01604540a6c873f4a731982d",
      "e9a01115c75b499884f7e0ef32e9e599",
      "5faba4ad609448b2b49024add4ad3b8e",
      "ef25efa751304e4699910f1fbc14345f",
      "0b44cb0f8e34446c8dde668a75d3d8ad",
      "edaac6587b2d4bd5be52b89bb097f99f",
      "7cb241365f604419af454c1c28de197a",
      "9cf586576ff44dba86ba2eb389593c61",
      "849b5c95008541d49f1ceedf0a59ac60",
      "f3665a86662746c4ac7cb0796604781d"
     ]
    },
    "id": "t7t_Uz0tdumL",
    "outputId": "d684e218-294e-4dc3-c8de-a01d397f021c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'elderly-grip-80' at:\n",
      "https://smith.langchain.com/o/3936adcd-6eec-4723-b49d-fee2168a2d46/datasets/8349afec-538d-4daa-bd7f-041c0c3c23f1/compare?selectedSessions=14cc06d7-bff2-4026-8e71-79b6582a0f37\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e019a376a2ae4965b5c4a7f22cd9cb96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.dopeness</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how many messages like 18 billion and 2.5 bill...</td>\n",
       "      <td>Based on the provided context:\\n\\n- By July 20...</td>\n",
       "      <td>None</td>\n",
       "      <td>According to the context, by July 2025, ChatGP...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.583190</td>\n",
       "      <td>1b70ae01-fc3a-4d47-a8f4-6f6b251b1fb8</td>\n",
       "      <td>6e45d7ed-58a7-4ce2-b06f-f6748cefb5f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what happen in july 2025 with chatgpt and how ...</td>\n",
       "      <td>In July 2025, ChatGPT had more than 700 millio...</td>\n",
       "      <td>None</td>\n",
       "      <td>In July 2025, ChatGPT had been used weekly by ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.579342</td>\n",
       "      <td>be6eb518-9138-463c-8cc0-2b97c678439c</td>\n",
       "      <td>b8618610-d994-4485-be6b-93139fa241bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does the growth of ChatGPT usage in the US...</td>\n",
       "      <td>Based on the context provided, the growth of C...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that in the US, ChatGPT ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.273568</td>\n",
       "      <td>8cb54345-757e-454e-b2a8-180bc55bb14b</td>\n",
       "      <td>1f296f3f-81a4-4bcf-a990-db4192d12029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wht US us ChatGPT for work and non-work?</td>\n",
       "      <td>Based on the provided context, users in the US...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that in the US, ChatGPT ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.138035</td>\n",
       "      <td>7a8d1800-b7ae-45cd-8900-a442c8227988</td>\n",
       "      <td>db87c9e5-d7f8-4217-956b-7b405fceb550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on the data showing the growth in non-wo...</td>\n",
       "      <td>Based on the context, a professional tech mana...</td>\n",
       "      <td>None</td>\n",
       "      <td>The data indicates that non-work messages have...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.218759</td>\n",
       "      <td>cb8c9822-fdad-40ba-baab-e25845d30e7f</td>\n",
       "      <td>fec4613d-1e2a-49bf-bd59-7424e0be58af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does the increase in total ChatGPT message...</td>\n",
       "      <td>Between June 2024 and June 2025, the total dai...</td>\n",
       "      <td>None</td>\n",
       "      <td>Between June 2024 and June 2025, total ChatGPT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.115514</td>\n",
       "      <td>b05f1401-16f3-45fd-9742-32eed880fe1d</td>\n",
       "      <td>68edf107-3a02-4f26-bf9a-80a02972d7bc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does the growth and adoption of ChatGPT re...</td>\n",
       "      <td>Based on the provided context, the growth and ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The rapid growth of ChatGPT, launched in Novem...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.619710</td>\n",
       "      <td>9c41c3aa-120d-4846-b125-dd7b62a204d2</td>\n",
       "      <td>9334b907-b64c-4f3f-bc82-bfabe160a90f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ChatGPT launch impact on economy and jobs how ...</td>\n",
       "      <td>Based on the provided context, the launch and ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context explains that ChatGPT, launched in...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.624191</td>\n",
       "      <td>c51dde34-ffa9-44b7-9214-2a052274ba0a</td>\n",
       "      <td>79106af0-b53d-4466-b00b-f2c585d93e90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does ChatGPT facilitate writing tasks for ...</td>\n",
       "      <td>Based on the provided context, ChatGPT facilit...</td>\n",
       "      <td>None</td>\n",
       "      <td>Writing is by far the most common work use of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.958922</td>\n",
       "      <td>0be31397-83da-41f7-b4be-0a43d29ca3fe</td>\n",
       "      <td>c2239f1f-b580-4573-9f97-f4377d4026c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do different occupation categories utilize...</td>\n",
       "      <td>Based on the provided context from the documen...</td>\n",
       "      <td>None</td>\n",
       "      <td>Variation by occupation shows that users in hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.819876</td>\n",
       "      <td>73d107e3-390b-44f5-81f9-ea0bc887ab41</td>\n",
       "      <td>22716e57-af5d-4d50-a368-b655d1bb5e0c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does the usage of ChatGPT messages in the ...</td>\n",
       "      <td>Based on the provided context from the documen...</td>\n",
       "      <td>None</td>\n",
       "      <td>According to the provided context, in the Unit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.364255</td>\n",
       "      <td>0c16c261-62aa-4b4b-a75e-091e38cfe12b</td>\n",
       "      <td>8e7cc1d4-e9c5-4a80-aadf-6e23b5cd22d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wha is the expexted growth of ChatGPT use by J...</td>\n",
       "      <td>By July 2025, ChatGPT had experienced rapid an...</td>\n",
       "      <td>None</td>\n",
       "      <td>By July 2025, 18 billion messages were being s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.596972</td>\n",
       "      <td>9c781fb0-81ee-4d1b-955b-f5f24d25e28b</td>\n",
       "      <td>1111174f-49fe-4b85-82ae-b6b00d729b7f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How does the rapid growth of ChatGPT, as an Op...</td>\n",
       "      <td>Based on the provided context, the rapid growt...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that ChatGPT, launched i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.577563</td>\n",
       "      <td>416a48fa-92f0-4ae9-adf3-7b5cd11e9780</td>\n",
       "      <td>31fbabcc-4df3-41f1-aab8-aa633b2d07bf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Whay did Handa et al. (2025) study the types o...</td>\n",
       "      <td>Handa et al. (2025) studied chatbot conversati...</td>\n",
       "      <td>None</td>\n",
       "      <td>Handa et al. (2025) studied the types of messa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.603089</td>\n",
       "      <td>32123748-08bd-4dcb-a3b1-9d31f184e7a4</td>\n",
       "      <td>b7e14d25-77b9-4393-a61d-b2ce7ceea43d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wht US is the main focus of the ChatGPT growth...</td>\n",
       "      <td>The study of ChatGPT growth primarily focuses ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The study highlights that ChatGPT's rapid grow...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.654316</td>\n",
       "      <td>b0ea227a-da62-494a-830b-858c8bcb65cd</td>\n",
       "      <td>3e684f6c-5734-47fd-a018-e3985828bdc3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Considering the rapid growth of ChatGPT usage ...</td>\n",
       "      <td>Based on the provided context, the rapid growt...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that in the US, ChatGPT ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.592013</td>\n",
       "      <td>b1134664-be8f-49e1-b038-52841ac49ca7</td>\n",
       "      <td>7b00af34-35f0-42b3-a1b6-fe1cc0abe022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hw does ChatGPT usage grow for work and non-wo...</td>\n",
       "      <td>Based on the provided context:\\n\\n- ChatGPT us...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that since its launch in...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.875387</td>\n",
       "      <td>13e69ad5-acdb-45ff-bfde-0e6e533a44d0</td>\n",
       "      <td>25043e45-f4c5-4b1a-9dcf-b025060e7121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How do the differences in message types, such ...</td>\n",
       "      <td>Based on the provided context, differences in ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The data indicates that users in highly paid p...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.103098</td>\n",
       "      <td>e7c773f7-74f1-4e40-a569-496cbb025142</td>\n",
       "      <td>ea782fa4-11bc-425a-b459-5c53c63fdf74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How does the rapid adoption of ChatGPT, as evi...</td>\n",
       "      <td>The rapid adoption of ChatGPT, with over 18 bi...</td>\n",
       "      <td>None</td>\n",
       "      <td>The rapid adoption of ChatGPT, with its widesp...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.313512</td>\n",
       "      <td>1da8b292-44ce-4896-b7e2-c6bf00a3af51</td>\n",
       "      <td>4bbdd937-41d9-4fe3-bf19-2e5fedfd4d77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How does variation in ChatGPT usage by occupat...</td>\n",
       "      <td>Based on the provided context, variation in Ch...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that ChatGPT usage varie...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.148054</td>\n",
       "      <td>fc65227a-2a4f-47c9-808c-148b9eab7498</td>\n",
       "      <td>e38f456a-60e2-4346-9793-92cbad59401f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Whn was November 2022 in relation to ChatGPT's...</td>\n",
       "      <td>November 2022 was the launch date of ChatGPT t...</td>\n",
       "      <td>None</td>\n",
       "      <td>Conclusion This paper studies the rapid growth...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.884617</td>\n",
       "      <td>594ce9b6-9919-4ab7-9a73-1b41982b9d53</td>\n",
       "      <td>6ee487df-cf9f-463c-96b6-f5e24a3fbb8c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ChatGPT use work?</td>\n",
       "      <td>Based on the provided context, ChatGPT is used...</td>\n",
       "      <td>None</td>\n",
       "      <td>Variation by Occupation Figure 23 shows how Ch...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.479951</td>\n",
       "      <td>4144b3f1-4bb0-4767-b375-5dfee4c43f67</td>\n",
       "      <td>48c8a0a6-a2e3-47fb-a939-e400dfbfbdb4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What is the significance of June 2024 in the c...</td>\n",
       "      <td>June 2024 is significant in the context of Cha...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context reports on ChatGPT message counts ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.024103</td>\n",
       "      <td>d9fbc256-e5a6-46a2-bd45-7e43ae3d2017</td>\n",
       "      <td>14e3d77f-0257-4b81-8270-248a41cbdee7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What is a Roth?</td>\n",
       "      <td>Based on the provided context, \"Roth\" appears ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The provided context does not include a defini...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.909320</td>\n",
       "      <td>87c382f5-b1ce-49b3-893c-7bcdb36d9655</td>\n",
       "      <td>b36e72ef-5a32-4271-b9a8-a28aec5e172a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>what is the relevence of july 2025 in the cont...</td>\n",
       "      <td>July 2025 is a key reference point in the cont...</td>\n",
       "      <td>None</td>\n",
       "      <td>by july 2025, chatgpt had been used weekly by ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.064820</td>\n",
       "      <td>df6d1093-e388-4d3d-ac87-a6077a9b006a</td>\n",
       "      <td>d8998ffd-9062-420e-a603-63e9c84bcd76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Based on the data indicating that 18 billion m...</td>\n",
       "      <td>Based on the provided context, by July 2025, C...</td>\n",
       "      <td>None</td>\n",
       "      <td>By July 2025, ChatGPT experienced a significan...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.235270</td>\n",
       "      <td>c0012cef-3c0c-4f99-87e7-d82e271aeff6</td>\n",
       "      <td>e8f83cf8-e6c4-4255-85c9-87441766b481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Based on the findings of Handa et al. (2025) r...</td>\n",
       "      <td>Based on the findings reported in the provided...</td>\n",
       "      <td>None</td>\n",
       "      <td>According to Handa et al. (2025), while both w...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.288161</td>\n",
       "      <td>3233b682-f836-4992-bb2f-3822b97757c6</td>\n",
       "      <td>018bc2c0-d89a-4f14-ba60-642e7493b390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>how Handa et al., 2025 talk about ChatGPT usag...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>Handa et al., 2025 discuss ChatGPT usage by an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.435455</td>\n",
       "      <td>90789415-854a-4a30-a5a8-f20ee9932926</td>\n",
       "      <td>886f18b0-c33a-4fa5-b106-13bb129ae65c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hw does AI-societal effects influence user-beh...</td>\n",
       "      <td>Based on the provided context, AI's societal e...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context explains that the rapid growth and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.392775</td>\n",
       "      <td>81485c9a-7b91-43db-80ee-35f28717882f</td>\n",
       "      <td>990a9267-5336-410f-b380-f6d18668b685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ChatGPT use work non-work topics practical gui...</td>\n",
       "      <td>Based on the provided context:\\n\\nChatGPT usag...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context shows that about 70% of ChatGPT qu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.777998</td>\n",
       "      <td>22d65d04-f334-45d9-945f-7ea4a7ba6751</td>\n",
       "      <td>86c3dc14-170f-41c8-80e0-2b5f210550f6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Considering the rapid growth and widespread ad...</td>\n",
       "      <td>Based on the provided context, the rapid adopt...</td>\n",
       "      <td>None</td>\n",
       "      <td>The rapid growth of ChatGPT, launched in Novem...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.756528</td>\n",
       "      <td>7c0f0fbd-5006-497d-83fb-08b8830d01c3</td>\n",
       "      <td>416e1013-cebb-48c7-b983-b5b9fbdc2fa5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Based on the data showing that non-work messag...</td>\n",
       "      <td>Based on the provided context, the usage patte...</td>\n",
       "      <td>None</td>\n",
       "      <td>The data indicates that by June 2025, non-work...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.210058</td>\n",
       "      <td>828d3eed-0247-4d10-b580-8c92e3af93a5</td>\n",
       "      <td>0405a4a5-9102-4a36-8b83-b8e9d88f72e0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>How does Writing relate to ChatGPT usage in th...</td>\n",
       "      <td>Based on the provided context, Writing is a ce...</td>\n",
       "      <td>None</td>\n",
       "      <td>Writing is by far the most common work use, ac...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.495127</td>\n",
       "      <td>c67f3c1b-68ea-42a8-8c07-5349cd41d4b3</td>\n",
       "      <td>58d46f62-a4ef-4fda-ac59-84a502f6f43b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SOC2 code 15 what is it</td>\n",
       "      <td>SOC2 code 15 corresponds to \"Computer-related\"...</td>\n",
       "      <td>None</td>\n",
       "      <td>Variation by Occupation Figure 23 reports on C...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.160206</td>\n",
       "      <td>fee37d73-c858-4274-b5cf-4cc111c0bece</td>\n",
       "      <td>22676a00-fe01-4fe1-8509-d4e753b9e022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>What is the significance of June 2025 in ChatG...</td>\n",
       "      <td>June 2025 is significant in ChatGPT usage tren...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that the report includes...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.376293</td>\n",
       "      <td>f0a15cd9-de2e-4be2-9601-aa387480c7d8</td>\n",
       "      <td>31a52acb-870c-424d-a13c-9fda3c5321c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Wha is the siginficance of Ling and Imas, 2025...</td>\n",
       "      <td>Ling and Imas (2025) are mentioned in the cont...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context references Ling and Imas, 2025 as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.168922</td>\n",
       "      <td>6c696c1a-6ebf-434e-8e23-496f57dcb709</td>\n",
       "      <td>615ae0dd-83e6-4b3a-adb3-6dea419273b7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults elderly-grip-80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    rag_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        dopeness_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"default_chain_init\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nq7fCVinrpI4"
   },
   "source": [
    "## Dope-ifying Our Application\n",
    "\n",
    "We'll be making a few changes to our RAG chain to increase its performance on our SDG evaluation test dataset!\n",
    "\n",
    "- Include a \"dope\" prompt augmentation\n",
    "- Use larger chunks\n",
    "- Improve the retriever model to: `text-embedding-3-large`\n",
    "\n",
    "Let's see how this changes our evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "z56pXwyUgFUt"
   },
   "outputs": [],
   "source": [
    "DOPENESS_RAG_PROMPT = \"\"\"\\\n",
    "Given a provided context and question, you must answer the question based only on context.\n",
    "\n",
    "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
    "\n",
    "Make your answer rad, ensure high levels of dopeness. Do not be generic, or give generic responses.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "dopeness_rag_prompt = ChatPromptTemplate.from_template(DOPENESS_RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "rZLcTstJgfv5"
   },
   "outputs": [],
   "source": [
    "rag_documents = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-LYsyirngj6n"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "rag_documents = text_splitter.split_documents(rag_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spldiPuTCzDO"
   },
   "source": [
    "#### ❓Question #2:\n",
    "\n",
    "Why would modifying our chunk size modify the performance of our application?\n",
    "\n",
    "Chunk size is raised from 500 to 1000.\n",
    "This provides better context . Similar context texts less likely to be truncated.  This leads to more complex idea structure, and better semantic coherence. On the downside, there are more tokesn, and processing is more costly and takes longer. \n",
    " 1. The questions generated by RAGAS tend to be more complex (multi-hop, abstract queries)\n",
    " 2. Larger chunks provide better context for answering these sophisticated questions - more helpful and nuanced answer.\n",
    " 3. The \"dopeness\" evaluator benefits from having more context to generate engaging, comprehensive responses.\n",
    " 4. All this at a cost of increased computation time and resource (cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "b9MI2Bm2go1r"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBbjG6cKC8BQ"
   },
   "source": [
    "#### ❓Question #3:\n",
    "\n",
    "Why would modifying our embedding model modify the performance of our application?\n",
    "\n",
    " 1. Better embedding model have higher dimesion which better captures semantic understanding.\n",
    " 2. This allow captures of more nuanced semantic relationship.\n",
    " 3. This leads to better query understanding and retrival informations. As in question 2 the downside is increased computation resource - cost and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "hVUY25FKgxXx"
   },
   "outputs": [],
   "source": [
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=rag_documents,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"Use Case RAG Docs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Q4TOZNYIg2v1"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqYGFrnKDB91"
   },
   "source": [
    "Setting up our new and improved DOPE RAG CHAIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "HqnTqeXMhAdx"
   },
   "outputs": [],
   "source": [
    "dopeness_rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | dopeness_rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21pTxoqJDI1Y"
   },
   "source": [
    "Let's test it on the same output that we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "OfZZ3MoN3fKv",
    "outputId": "d65722dd-92c2-4e4e-9cca-c42ee6f3f208"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Alright, buckle up! Based on the context from this fresh 2025 brain dump, people are straight-up flexing AI like ChatGPT to turbocharge their money-making game in a few slick ways.\\n\\nFirstly, AI isn’t just some magic button to do your job for you—it’s more like the ultimate sidekick, giving killer advice and research support. This means folks are leveraging AI as a savvy advisor, cranking up their decision-making chops, especially in brainy, knowledge-heavy gigs. Smarter decisions = better output = more $$$. \\n\\nCollis and Brynjolfsson’s 2025 study drops the mic here: US users would need a whopping $98 to skip out on generative AI for a month — implying the economic boost from AI is over $97 billion annually. That’s wild surplus value flowing because workers are not just using AI as an assistant but as a productivity amplifier. Whether it's automating tasks or guiding choices (hello, decision support system vibes), AI is remixing how people do work, making the grind both smoother and more productive.\\n\\nSo the rad truth? People are turning AI into their money-making secret weapon by using it to *augment* their skills—sharpening decisions, speeding research, and powering through work smarter, not just harder. It’s not robots taking over; it’s humans and AI leveling up together and stacking that paper.\\n\\nBoom.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dopeness_rag_chain.invoke({\"question\" : \"How are people using AI to make money?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpj7v1inDLnQ"
   },
   "source": [
    "Finally, we can evaluate the new chain on the same test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "bf8dcc0895054529af356da401c513f6",
      "7dce19ac55264f2b88a0e4730e55867b",
      "2a0755d4476543feb4a64538e3e37213",
      "158212a630f04cbd884c937f2f60f5c8",
      "11c7f66acc1d45be9517d0addf49331e",
      "ddffd834e09940a4bd3874c3f39b4e21",
      "ef63c3b2d51e452da03cdae5d9b034be",
      "c20b539cd70b4ba99601ad1d69fd9cec",
      "a6d681eeafa44d18b933a4c5dec88382",
      "d1d54ccd56494c4d831f71b416a1f880",
      "530f696feefe499da08c6312047379b2"
     ]
    },
    "id": "Dx11S2b-hIM8",
    "outputId": "d3a3ea78-aa32-4bd2-8c2a-d0d0303695c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'definite-coast-37' at:\n",
      "https://smith.langchain.com/o/3936adcd-6eec-4723-b49d-fee2168a2d46/datasets/8349afec-538d-4daa-bd7f-041c0c3c23f1/compare?selectedSessions=b2d01397-839d-49c6-a12e-5b176d6a9269\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f4f1c7b4bf4875b1faab4dad5afb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.dopeness</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how many messages like 18 billion and 2.5 bill...</td>\n",
       "      <td>Alright, strap in for some next-level AI juice...</td>\n",
       "      <td>None</td>\n",
       "      <td>According to the context, by July 2025, ChatGP...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.234436</td>\n",
       "      <td>1b70ae01-fc3a-4d47-a8f4-6f6b251b1fb8</td>\n",
       "      <td>953fa4d0-031a-45cc-aa8f-a062edf98787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what happen in july 2025 with chatgpt and how ...</td>\n",
       "      <td>Yo, let's drop some sick knowledge from that f...</td>\n",
       "      <td>None</td>\n",
       "      <td>In July 2025, ChatGPT had been used weekly by ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.144565</td>\n",
       "      <td>be6eb518-9138-463c-8cc0-2b97c678439c</td>\n",
       "      <td>bdd891c5-d78f-48bd-819c-8f9fdfcadf12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does the growth of ChatGPT usage in the US...</td>\n",
       "      <td>Alright, buckle up — this is some seriously sl...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that in the US, ChatGPT ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.152414</td>\n",
       "      <td>8cb54345-757e-454e-b2a8-180bc55bb14b</td>\n",
       "      <td>c77b2ba5-f4df-47b4-a84e-4ddb3879dd3e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wht US us ChatGPT for work and non-work?</td>\n",
       "      <td>Alright, let's crank this up to eleven and dro...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that in the US, ChatGPT ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.678231</td>\n",
       "      <td>7a8d1800-b7ae-45cd-8900-a442c8227988</td>\n",
       "      <td>5c50a528-9728-44aa-8975-274ee642fb6c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on the data showing the growth in non-wo...</td>\n",
       "      <td>Alright, buckle up — here’s how a sharp tech m...</td>\n",
       "      <td>None</td>\n",
       "      <td>The data indicates that non-work messages have...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.162671</td>\n",
       "      <td>cb8c9822-fdad-40ba-baab-e25845d30e7f</td>\n",
       "      <td>2a7f6ea1-d78e-4cf1-985d-eb5f5cce7908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does the increase in total ChatGPT message...</td>\n",
       "      <td>Alright, buckle up for some sizzling AI usage ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Between June 2024 and June 2025, total ChatGPT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.982502</td>\n",
       "      <td>b05f1401-16f3-45fd-9742-32eed880fe1d</td>\n",
       "      <td>3fde20c8-7f16-4434-8098-e005d8164356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does the growth and adoption of ChatGPT re...</td>\n",
       "      <td>Yo, here’s the 411 straight from the dopest AI...</td>\n",
       "      <td>None</td>\n",
       "      <td>The rapid growth of ChatGPT, launched in Novem...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.675610</td>\n",
       "      <td>9c41c3aa-120d-4846-b125-dd7b62a204d2</td>\n",
       "      <td>aa686942-edbc-46a7-aca4-14cd6d2be2b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ChatGPT launch impact on economy and jobs how ...</td>\n",
       "      <td>Yo, strap in for this AI-powered economic and ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context explains that ChatGPT, launched in...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.676010</td>\n",
       "      <td>c51dde34-ffa9-44b7-9214-2a052274ba0a</td>\n",
       "      <td>b7e513d9-1de7-4ab3-97b6-980d760dea29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does ChatGPT facilitate writing tasks for ...</td>\n",
       "      <td>Oh, buckle up, because ChatGPT is the ultimate...</td>\n",
       "      <td>None</td>\n",
       "      <td>Writing is by far the most common work use of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.911931</td>\n",
       "      <td>0be31397-83da-41f7-b4be-0a43d29ca3fe</td>\n",
       "      <td>35e7b076-2098-4b0b-add8-d1a27a44e00f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do different occupation categories utilize...</td>\n",
       "      <td>Alright, buckle up for the ultimate dive into ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Variation by occupation shows that users in hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.380189</td>\n",
       "      <td>73d107e3-390b-44f5-81f9-ea0bc887ab41</td>\n",
       "      <td>84d29ef8-d5bb-4a2d-a907-a3fac9c7a9ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does the usage of ChatGPT messages in the ...</td>\n",
       "      <td>Alright, let’s dive into this ChatGPT hustle i...</td>\n",
       "      <td>None</td>\n",
       "      <td>According to the provided context, in the Unit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.777965</td>\n",
       "      <td>0c16c261-62aa-4b4b-a75e-091e38cfe12b</td>\n",
       "      <td>866f72ac-9afd-40a1-874a-29cdc77f525f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wha is the expexted growth of ChatGPT use by J...</td>\n",
       "      <td>Yo, check this out—ChatGPT’s growth story is s...</td>\n",
       "      <td>None</td>\n",
       "      <td>By July 2025, 18 billion messages were being s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.399431</td>\n",
       "      <td>9c781fb0-81ee-4d1b-955b-f5f24d25e28b</td>\n",
       "      <td>655509e2-f979-4b2f-9b2d-8dc4f9812320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How does the rapid growth of ChatGPT, as an Op...</td>\n",
       "      <td>Oh, buckle up — the ChatGPT rocket isn’t just ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that ChatGPT, launched i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.870244</td>\n",
       "      <td>416a48fa-92f0-4ae9-adf3-7b5cd11e9780</td>\n",
       "      <td>aee46717-bf52-43d7-9881-d31f6846c9f7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Whay did Handa et al. (2025) study the types o...</td>\n",
       "      <td>Yo, here’s the 411 straight from the context, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Handa et al. (2025) studied the types of messa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.359541</td>\n",
       "      <td>32123748-08bd-4dcb-a3b1-9d31f184e7a4</td>\n",
       "      <td>74a4d453-3fe2-42cc-881a-f4f86cbc3192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wht US is the main focus of the ChatGPT growth...</td>\n",
       "      <td>Yo, here’s the deal straight from the digital ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The study highlights that ChatGPT's rapid grow...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.221984</td>\n",
       "      <td>b0ea227a-da62-494a-830b-858c8bcb65cd</td>\n",
       "      <td>2fa8f0cc-6731-4d7a-8428-bb7b4510cf94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Considering the rapid growth of ChatGPT usage ...</td>\n",
       "      <td>Alright, let’s crank this up to eleven and dro...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that in the US, ChatGPT ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.371193</td>\n",
       "      <td>b1134664-be8f-49e1-b038-52841ac49ca7</td>\n",
       "      <td>84a99cbc-0fca-4579-8351-32d43dead2fd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hw does ChatGPT usage grow for work and non-wo...</td>\n",
       "      <td>Yo, let’s unpack this digital saga with some s...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that since its launch in...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.417719</td>\n",
       "      <td>13e69ad5-acdb-45ff-bfde-0e6e533a44d0</td>\n",
       "      <td>28c68124-2bdc-40df-b0aa-abd9e1fbb1a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How do the differences in message types, such ...</td>\n",
       "      <td>Alright, let's break down the wickedly cool in...</td>\n",
       "      <td>None</td>\n",
       "      <td>The data indicates that users in highly paid p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.311739</td>\n",
       "      <td>e7c773f7-74f1-4e40-a569-496cbb025142</td>\n",
       "      <td>a317dc91-efef-42d1-b8fe-c32f7187fa62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How does the rapid adoption of ChatGPT, as evi...</td>\n",
       "      <td>Yo, buckle up — the rapid rocket-speed adoptio...</td>\n",
       "      <td>None</td>\n",
       "      <td>The rapid adoption of ChatGPT, with its widesp...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.326978</td>\n",
       "      <td>1da8b292-44ce-4896-b7e2-c6bf00a3af51</td>\n",
       "      <td>b358ea67-629c-433c-931f-f82fc652c21c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How does variation in ChatGPT usage by occupat...</td>\n",
       "      <td>Alright, here’s the fly lowdown with major sty...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that ChatGPT usage varie...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.926462</td>\n",
       "      <td>fc65227a-2a4f-47c9-808c-148b9eab7498</td>\n",
       "      <td>cd87fded-f72b-4af2-a4f2-d1076fad0f74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Whn was November 2022 in relation to ChatGPT's...</td>\n",
       "      <td>Yo, November 2022 was the official kick-off pa...</td>\n",
       "      <td>None</td>\n",
       "      <td>Conclusion This paper studies the rapid growth...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.893795</td>\n",
       "      <td>594ce9b6-9919-4ab7-9a73-1b41982b9d53</td>\n",
       "      <td>908ca52e-ddea-4a65-a7dd-728169d94120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ChatGPT use work?</td>\n",
       "      <td>Oh heck yeah, ChatGPT puts in the work grind! ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Variation by Occupation Figure 23 shows how Ch...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.916532</td>\n",
       "      <td>4144b3f1-4bb0-4767-b375-5dfee4c43f67</td>\n",
       "      <td>9082aef3-1ad4-4c3e-9b77-9760d365555f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What is the significance of June 2024 in the c...</td>\n",
       "      <td>Alright, strap in for this data drop worthy of...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context reports on ChatGPT message counts ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.588076</td>\n",
       "      <td>d9fbc256-e5a6-46a2-bd45-7e43ae3d2017</td>\n",
       "      <td>ebce65bc-9d97-4404-9551-8bb60c3765be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What is a Roth?</td>\n",
       "      <td>I don’t know. The context didn’t drop any wisd...</td>\n",
       "      <td>None</td>\n",
       "      <td>The provided context does not include a defini...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.740278</td>\n",
       "      <td>87c382f5-b1ce-49b3-893c-7bcdb36d9655</td>\n",
       "      <td>3a496def-c251-4892-984e-87f50db5e911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>what is the relevence of july 2025 in the cont...</td>\n",
       "      <td>Yo, July 2025 is straight-up legendary in the ...</td>\n",
       "      <td>None</td>\n",
       "      <td>by july 2025, chatgpt had been used weekly by ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.439596</td>\n",
       "      <td>df6d1093-e388-4d3d-ac87-a6077a9b006a</td>\n",
       "      <td>00e63bc1-6236-41da-9402-d7fdf20fa4e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Based on the data indicating that 18 billion m...</td>\n",
       "      <td>Yo, brace yourself—ChatGPT’s usage exploded li...</td>\n",
       "      <td>None</td>\n",
       "      <td>By July 2025, ChatGPT experienced a significan...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.255454</td>\n",
       "      <td>c0012cef-3c0c-4f99-87e7-d82e271aeff6</td>\n",
       "      <td>b9a4ad6b-288c-4116-a64a-f296d0ea777e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Based on the findings of Handa et al. (2025) r...</td>\n",
       "      <td>Yo, check this: Between 2024 and 2025, work-re...</td>\n",
       "      <td>None</td>\n",
       "      <td>According to Handa et al. (2025), while both w...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.861725</td>\n",
       "      <td>3233b682-f836-4992-bb2f-3822b97757c6</td>\n",
       "      <td>843e0cbf-4c06-4a8b-b53c-b9defb54ab80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>how Handa et al., 2025 talk about ChatGPT usag...</td>\n",
       "      <td>Yo, here’s the lowdown straight from the digit...</td>\n",
       "      <td>None</td>\n",
       "      <td>Handa et al., 2025 discuss ChatGPT usage by an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.041493</td>\n",
       "      <td>90789415-854a-4a30-a5a8-f20ee9932926</td>\n",
       "      <td>7f0f27d7-0b4f-4c9a-b37a-e3f8e01745bd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hw does AI-societal effects influence user-beh...</td>\n",
       "      <td>Alright, buckle up — here’s the lowdown from t...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context explains that the rapid growth and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.095670</td>\n",
       "      <td>81485c9a-7b91-43db-80ee-35f28717882f</td>\n",
       "      <td>0848c370-49bb-49e2-883d-5e6daec752dd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ChatGPT use work non-work topics practical gui...</td>\n",
       "      <td>Alright, here’s the lowdown on how ChatGPT gro...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context shows that about 70% of ChatGPT qu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.828270</td>\n",
       "      <td>22d65d04-f334-45d9-945f-7ea4a7ba6751</td>\n",
       "      <td>72d31547-23ff-4e6a-a745-e5a4463692b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Considering the rapid growth and widespread ad...</td>\n",
       "      <td>Alright, let’s blast off into the cosmic deep ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The rapid growth of ChatGPT, launched in Novem...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.593897</td>\n",
       "      <td>7c0f0fbd-5006-497d-83fb-08b8830d01c3</td>\n",
       "      <td>835ee643-22d8-4e43-b18d-0955fcf03956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Based on the data showing that non-work messag...</td>\n",
       "      <td>Yo, buckle up — this is where ChatGPT’s dance ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The data indicates that by June 2025, non-work...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.035661</td>\n",
       "      <td>828d3eed-0247-4d10-b580-8c92e3af93a5</td>\n",
       "      <td>3b1e0720-f7e7-40ef-9aba-57b27f2829aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>How does Writing relate to ChatGPT usage in th...</td>\n",
       "      <td>Yo, buckle up—here’s the lowdown on Writing wi...</td>\n",
       "      <td>None</td>\n",
       "      <td>Writing is by far the most common work use, ac...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.456203</td>\n",
       "      <td>c67f3c1b-68ea-42a8-8c07-5349cd41d4b3</td>\n",
       "      <td>4854849e-50db-4e69-9719-bd6f365f02e7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SOC2 code 15 what is it</td>\n",
       "      <td>Oh snap, you’re diving into the sick world of ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Variation by Occupation Figure 23 reports on C...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.283344</td>\n",
       "      <td>fee37d73-c858-4274-b5cf-4cc111c0bece</td>\n",
       "      <td>094d310b-c178-4678-971e-d8a0e845bb9d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>What is the significance of June 2025 in ChatG...</td>\n",
       "      <td>Alright, buckle up for the June 2025 scoop on ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that the report includes...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.166902</td>\n",
       "      <td>f0a15cd9-de2e-4be2-9601-aa387480c7d8</td>\n",
       "      <td>54b0d0c0-aca2-4b2a-9c79-4958badd6f3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Wha is the siginficance of Ling and Imas, 2025...</td>\n",
       "      <td>Yo, Ling and Imas, 2025—these legends dropped ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context references Ling and Imas, 2025 as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.053280</td>\n",
       "      <td>6c696c1a-6ebf-434e-8e23-496f57dcb709</td>\n",
       "      <td>9d6a62a1-d9be-46c9-a9ca-b6d5adaaa8ef</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults definite-coast-37>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    dopeness_rag_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        dopeness_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"dopeness_rag_chain\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C7migvlDPZT"
   },
   "source": [
    "#### 🏗️ Activity #3:\n",
    "\n",
    "Provide a screenshot of the difference between the two chains, and explain why you believe certain metrics changed in certain ways.\n",
    "\n",
    "Dopeness improves as prompt augementation makes response more targeted.\n",
    "\n",
    "Correctness dropped as large chunk may have introduced noise in this case. Better embedding model may retrivve contextually similar but factually incorrect information. Helpfulness may drop for similar reasons.\n",
    "\n",
    "#### This suggests \n",
    "\n",
    "Engagement vs. Utility: The \"dope\" responses might be more entertaining but affects accuracy. Facts may be boring.\n",
    "Information Overload: Larger chunks might be providing too much context, making responses less focused\n",
    "Style vs. Substance: The evaluator might prefer straightforward, factual responses over engaging ones\n",
    "\n",
    "#### What this neans is that \n",
    "\n",
    "For Different Use Cases: You might want different chains for different scenarios\n",
    "Recommendations:\n",
    "Hybrid Approach: Use different chains for different types of questions\n",
    "No one size fits all!  **Always evaluate**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Screenshot: Chunk size 500,    embeddings \"text-embedding-3-small\"\n",
    "\n",
    "![500_chunk_embeddings_small](data/chain1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Screenshot : Chunk size 1000,  embeddings \"text-embedding-3-large\"\n",
    "\n",
    "![1000_chunks_embeddings_large](data/chain2.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07ab3dc0790241bbb85a7f488a42ef8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7710c7377cbc4c30b55b28b4bc99e88f",
       "IPY_MODEL_41bdd49fab5f4826959d0d50663ff539",
       "IPY_MODEL_60168d85131d4afc99d55d61ab954ee6"
      ],
      "layout": "IPY_MODEL_9edf898aeeab40dda9b9475395776521"
     }
    },
    "095f680d37a3430fb82d223615662db5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b44cb0f8e34446c8dde668a75d3d8ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10df31709059484c99f102453d780473": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1160a44dc18e47b0890f70c40eaa7eb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11c7f66acc1d45be9517d0addf49331e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "122b1bd1f0e9417a8dcb57d4eebe4d2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0c233ad01604540a6c873f4a731982d",
       "IPY_MODEL_e9a01115c75b499884f7e0ef32e9e599",
       "IPY_MODEL_5faba4ad609448b2b49024add4ad3b8e"
      ],
      "layout": "IPY_MODEL_ef25efa751304e4699910f1fbc14345f"
     }
    },
    "158212a630f04cbd884c937f2f60f5c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1d54ccd56494c4d831f71b416a1f880",
      "placeholder": "​",
      "style": "IPY_MODEL_530f696feefe499da08c6312047379b2",
      "value": " 20/? [01:43&lt;00:00,  5.25s/it]"
     }
    },
    "23863bc37a8645029934b8c106622c51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2508d229935744cbb5fc340222e2d660": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a0755d4476543feb4a64538e3e37213": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c20b539cd70b4ba99601ad1d69fd9cec",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6d681eeafa44d18b933a4c5dec88382",
      "value": 1
     }
    },
    "33f063017b7c4c7fa8cbafc89674350b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6864c81e2bcf459bbaf5acbb36bdfcbe",
       "IPY_MODEL_59d6e269eadf429a924f6f79bc8ba4ba",
       "IPY_MODEL_ca791fc471e34b9da2f9070fc1053c0f"
      ],
      "layout": "IPY_MODEL_8baf0ed3d0f743f294e07f2b5407e820"
     }
    },
    "3a8537e37fc14fd9b16ca0ceee4fede6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41bdd49fab5f4826959d0d50663ff539": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6eb8b2e3262c45248708a2082c366f0a",
      "max": 64,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_095f680d37a3430fb82d223615662db5",
      "value": 64
     }
    },
    "530f696feefe499da08c6312047379b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59d6e269eadf429a924f6f79bc8ba4ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_890e0dd7fa524ceca1e805cb6253ee71",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_61b52ff459214129b8f7e6d67b192b78",
      "value": 20
     }
    },
    "5ab5f08afa5841709aedb2f78a52a11c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c2fda99d4204d85b1bf7ad354fd58d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5faba4ad609448b2b49024add4ad3b8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_849b5c95008541d49f1ceedf0a59ac60",
      "placeholder": "​",
      "style": "IPY_MODEL_f3665a86662746c4ac7cb0796604781d",
      "value": " 20/? [01:27&lt;00:00,  6.45s/it]"
     }
    },
    "60168d85131d4afc99d55d61ab954ee6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a8537e37fc14fd9b16ca0ceee4fede6",
      "placeholder": "​",
      "style": "IPY_MODEL_1160a44dc18e47b0890f70c40eaa7eb0",
      "value": " 61/64 [00:02&lt;00:00, 23.36it/s]"
     }
    },
    "61b52ff459214129b8f7e6d67b192b78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6864c81e2bcf459bbaf5acbb36bdfcbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10df31709059484c99f102453d780473",
      "placeholder": "​",
      "style": "IPY_MODEL_2508d229935744cbb5fc340222e2d660",
      "value": "Generating: 100%"
     }
    },
    "6eb8b2e3262c45248708a2082c366f0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7710c7377cbc4c30b55b28b4bc99e88f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c2fda99d4204d85b1bf7ad354fd58d4",
      "placeholder": "​",
      "style": "IPY_MODEL_93cd4d35c5fd41f5904ca1d52d1f52a8",
      "value": "embedding nodes:  95%"
     }
    },
    "7cb241365f604419af454c1c28de197a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "7dce19ac55264f2b88a0e4730e55867b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddffd834e09940a4bd3874c3f39b4e21",
      "placeholder": "​",
      "style": "IPY_MODEL_ef63c3b2d51e452da03cdae5d9b034be",
      "value": ""
     }
    },
    "849b5c95008541d49f1ceedf0a59ac60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "890e0dd7fa524ceca1e805cb6253ee71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8baf0ed3d0f743f294e07f2b5407e820": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93cd4d35c5fd41f5904ca1d52d1f52a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9cf586576ff44dba86ba2eb389593c61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9edf898aeeab40dda9b9475395776521": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "a6d681eeafa44d18b933a4c5dec88382": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf8dcc0895054529af356da401c513f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7dce19ac55264f2b88a0e4730e55867b",
       "IPY_MODEL_2a0755d4476543feb4a64538e3e37213",
       "IPY_MODEL_158212a630f04cbd884c937f2f60f5c8"
      ],
      "layout": "IPY_MODEL_11c7f66acc1d45be9517d0addf49331e"
     }
    },
    "c20b539cd70b4ba99601ad1d69fd9cec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "ca791fc471e34b9da2f9070fc1053c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23863bc37a8645029934b8c106622c51",
      "placeholder": "​",
      "style": "IPY_MODEL_5ab5f08afa5841709aedb2f78a52a11c",
      "value": " 20/20 [00:52&lt;00:00,  4.50s/it]"
     }
    },
    "d1d54ccd56494c4d831f71b416a1f880": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddffd834e09940a4bd3874c3f39b4e21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0c233ad01604540a6c873f4a731982d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b44cb0f8e34446c8dde668a75d3d8ad",
      "placeholder": "​",
      "style": "IPY_MODEL_edaac6587b2d4bd5be52b89bb097f99f",
      "value": ""
     }
    },
    "e9a01115c75b499884f7e0ef32e9e599": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cb241365f604419af454c1c28de197a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9cf586576ff44dba86ba2eb389593c61",
      "value": 1
     }
    },
    "edaac6587b2d4bd5be52b89bb097f99f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef25efa751304e4699910f1fbc14345f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef63c3b2d51e452da03cdae5d9b034be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3665a86662746c4ac7cb0796604781d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "state": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
